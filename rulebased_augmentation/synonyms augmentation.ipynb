{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from time import sleep\n",
    "import requests\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "from rnnmorph.predictor import RNNMorphPredictor\n",
    "\n",
    "predictor = RNNMorphPredictor(language=\"ru\")\n",
    "morph = MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# possible errors: no word in the dict ('div', class_=\"v3-none-text\"), word with spelling mistake (тето ('div', class_=\"v2-spelling-flash-outer\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = {'nom': 'nomn',\n",
    "              'gen': 'gent',\n",
    "              'dat': 'datv',\n",
    "              'acc': 'accs',\n",
    "              'ins': 'ablt',\n",
    "              'loc': 'loct',\n",
    "              'masc': 'masc',\n",
    "              'fem': 'femn',\n",
    "              'neut': 'neut'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All functions definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_synonym(normal_form, gender=None):\n",
    "    headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/39.0.2171.95 Safari/537.36'}\n",
    "    if os.path.exists('synonyms.txt'):\n",
    "        with open('synonyms.txt') as synonyms_cache:\n",
    "            synonyms_cache = [x.strip().split() for x in synonyms_cache]\n",
    "            synonyms_cache = {(form, gen):syn for form, gen, syn in synonyms_cache}\n",
    "        if (normal_form, str(gender)) in synonyms_cache:\n",
    "            #print('yes')\n",
    "            return synonyms_cache[(normal_form, str(gender))]\n",
    "    try:\n",
    "        content = requests.get(f'https://kartaslov.ru/синонимы-к-слову/{normal_form}', headers=headers).content\n",
    "    except ConnectionError:\n",
    "        print('Sleeping')\n",
    "        sleep(5)\n",
    "        try:\n",
    "            content = requests.get(f'https://kartaslov.ru/синонимы-к-слову/{normal_form}', headers=headers).content\n",
    "        except ConnectionError:\n",
    "            print('no')\n",
    "            return None\n",
    "    soup = BeautifulSoup(content)\n",
    "    #print(normal_form)\n",
    "    if soup.findAll('div', class_=\"v3-none-text\"):\n",
    "        return None\n",
    "    synonyms_page = soup.findAll('ul')\n",
    "    if len(synonyms_page) > 1:\n",
    "        synonyms = sum([x.text.strip().split(', ') for x in synonyms_page[1].findAll('li')], [])\n",
    "        synonyms = [x for x in synonyms if ' ' not in x and '\\xa0' not in x]\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "    # ADD CHECK WITH W2V\n",
    "    #print(synonyms)\n",
    "    if not synonyms:\n",
    "        return None\n",
    "    if gender:\n",
    "        try:\n",
    "            synonym = list(filter(lambda x: gender in x.tag, predictor.predict(synonyms)))[0].word\n",
    "        except IndexError:\n",
    "            synonym = None\n",
    "    else:\n",
    "        synonym = synonyms[0]\n",
    "    #print(synonym)\n",
    "    if synonym is not None:\n",
    "        with open('synonyms.txt', 'a') as synonyms_cache:\n",
    "            synonyms_cache.write(f'{normal_form} {gender} {synonym}'+'\\n')\n",
    "    return synonym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_nouns(source_sentence, num=1):\n",
    "    target_sentence = source_sentence.copy()\n",
    "\n",
    "    candidate_forms = list(filter(lambda x: x.pos == 'NOUN', predictor.predict(source_sentence)))[:num]\n",
    "    for form in candidate_forms:\n",
    "        case_num = re.search('case=(.+)\\|.+number=(.+)', form.tag.lower())\n",
    "        gender = re.search('Gender=(.+)\\|', form.tag)\n",
    "        if gender:\n",
    "            gender = gender.group(1)\n",
    "        else:\n",
    "            continue\n",
    "        tags = {transforms[case_num.group(1)], case_num.group(2)}\n",
    "        \n",
    "        synonym = find_synonym(form.normal_form, gender)\n",
    "        if synonym is None:\n",
    "            continue\n",
    "        inflected_word = list(filter(lambda x : x.tag.POS in ['NOUN'], morph.parse(synonym)))\n",
    "        if inflected_word:\n",
    "            #print(inflected_word[0], tags, inflected_word[0].inflect(tags))\n",
    "            inflected_word = inflected_word[0].inflect(tags)\n",
    "            if inflected_word:\n",
    "                inflected_word = inflected_word.word\n",
    "            else:\n",
    "                continue\n",
    "        else:\n",
    "            continue\n",
    "        target_sentence[target_sentence.index(form.word)] = inflected_word\n",
    "    return target_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_adjectives(source_sentence, num=1):\n",
    "    target_sentence = source_sentence.copy()\n",
    "\n",
    "    candidate_forms = list(filter(lambda x: x.pos == 'ADJ', predictor.predict(source_sentence)))[:num]\n",
    "    for form in candidate_forms:\n",
    "        case = re.search('case=(.{3})\\|.+', form.tag.lower())\n",
    "        num = re.search('number=(.{4})', form.tag.lower())\n",
    "        #print(form)\n",
    "        if not num:\n",
    "            continue\n",
    "        if num.group(1) == 'plur':\n",
    "            gender = None\n",
    "            if case:\n",
    "                tags = {transforms[case.group(1)], num.group(1)}\n",
    "            else:\n",
    "                tags = {num.group(1)}\n",
    "        else:\n",
    "            gender = re.search('gender=(.{3,4})\\|.+', form.tag.lower()).group(1)\n",
    "            if not case:\n",
    "                #print(12, num.group(1), case_num)\n",
    "                tags = {num.group(1), transforms[gender]}\n",
    "            else:\n",
    "                tags = {transforms[case.group(1)], num.group(1), transforms[gender]}\n",
    "        \n",
    "        #print(tags)\n",
    "        synonym = find_synonym(form.normal_form)\n",
    "        if synonym is None:\n",
    "            continue\n",
    "        inflected_word = list(filter(lambda x : x.tag.POS in ['ADJF'], morph.parse(synonym)))\n",
    "        if inflected_word:\n",
    "            inflected_word = inflected_word[0].inflect(tags).word\n",
    "        else:\n",
    "            continue\n",
    "        target_sentence[target_sentence.index(form.word)] = inflected_word\n",
    "    return target_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_adverbs(source_sentence, num=1):\n",
    "    target_sentence = source_sentence.copy()\n",
    "\n",
    "    candidate_forms = list(filter(lambda x: x.pos == 'ADV', predictor.predict(source_sentence)))[:num]\n",
    "    for form in candidate_forms:\n",
    "        synonym = find_synonym(form.normal_form)\n",
    "        if synonym is None:\n",
    "            continue\n",
    "        else:\n",
    "            target_sentence[target_sentence.index(form.word)] = synonym\n",
    "    return target_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modify_sentences(src, tgt):\n",
    "    modified_src = []\n",
    "    modified_tgt = []\n",
    "    for num, (src_sentence, sentence) in enumerate(zip(src, tgt)):\n",
    "        #print(sentence)\n",
    "        modified_sentence = replace_nouns(sentence)\n",
    "        if modified_sentence == sentence:\n",
    "            modified_sentence = replace_adverbs(sentence)\n",
    "            if modified_sentence == sentence:\n",
    "                modified_sentence = replace_adjectives(sentence)\n",
    "                if modified_sentence == sentence:\n",
    "                    continue\n",
    "        modified_src.append(src_sentence)\n",
    "        modified_tgt.append(modified_sentence)\n",
    "        if num % 50 == 0:\n",
    "            print(f'{num}/{len(src)}')\n",
    "    return modified_src, modified_tgt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/4525\n",
      "50/4525\n",
      "100/4525\n",
      "200/4525\n",
      "250/4525\n",
      "300/4525\n",
      "400/4525\n",
      "450/4525\n",
      "500/4525\n",
      "650/4525\n",
      "700/4525\n",
      "750/4525\n",
      "800/4525\n",
      "850/4525\n",
      "950/4525\n",
      "1000/4525\n",
      "1050/4525\n",
      "1150/4525\n",
      "1200/4525\n",
      "1250/4525\n",
      "1300/4525\n",
      "1350/4525\n",
      "1500/4525\n",
      "1550/4525\n",
      "1700/4525\n",
      "1900/4525\n",
      "1950/4525\n",
      "2000/4525\n",
      "2100/4525\n",
      "2150/4525\n",
      "2200/4525\n",
      "2250/4525\n",
      "2300/4525\n",
      "2350/4525\n",
      "2400/4525\n",
      "2500/4525\n",
      "2600/4525\n",
      "2700/4525\n",
      "2750/4525\n",
      "2800/4525\n",
      "2850/4525\n",
      "2900/4525\n",
      "2950/4525\n",
      "3000/4525\n",
      "3100/4525\n",
      "3150/4525\n",
      "3250/4525\n",
      "3300/4525\n",
      "3350/4525\n",
      "3400/4525\n",
      "3450/4525\n",
      "3500/4525\n",
      "3550/4525\n",
      "3600/4525\n",
      "3750/4525\n",
      "3850/4525\n",
      "3900/4525\n",
      "3950/4525\n",
      "4000/4525\n",
      "4050/4525\n",
      "4100/4525\n",
      "4150/4525\n",
      "4250/4525\n",
      "4350/4525\n",
      "4400/4525\n",
      "4450/4525\n",
      "4500/4525\n"
     ]
    }
   ],
   "source": [
    "def augment(trainsetpath):\n",
    "    if not os.path.exists(f'{trainsetpath}_aug'):\n",
    "        os.mkdir(f'{trainsetpath}_aug')\n",
    "    with open(f'{trainsetpath}/src-train14r.txt') as srctrain, open(f'{trainsetpath}/tgt-train14r.txt') as tgttrain, open(f'{trainsetpath}_aug/src-train.txt', 'w') as aug_srctrain, open(f'{trainsetpath}_aug/tgt-train.txt', 'w') as aug_tgttrain:\n",
    "            srctrain = [x.strip().split() for x in srctrain]\n",
    "            tgttrain = [x.strip().split() for x in tgttrain]\n",
    "            aug_src, aug_tgt = modify_sentences(srctrain, tgttrain)\n",
    "            for src_line, tgt_line in zip(srctrain, tgttrain):\n",
    "                aug_srctrain.write(' '.join(src_line)+'\\n')\n",
    "                aug_tgttrain.write(' '.join(tgt_line)+'\\n')\n",
    "            for src_line, tgt_line in zip(aug_src, aug_tgt):\n",
    "                aug_srctrain.write(' '.join(src_line)+'\\n')\n",
    "                aug_tgttrain.write(' '.join(tgt_line)+'\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check that the functions work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['так', 'живем', 'сейчас'],\n",
       " ['костры', 'разжег', 'отец'],\n",
       " ['потом', 'большой'],\n",
       " ['говорит', 'если', 'олени', 'потеряются'],\n",
       " ['у', 'тебя', 'опыт', 'большой'],\n",
       " ['я', 'в', 'берлогу', 'зашла'],\n",
       " ['там', 'один', 'или', 'два', 'года', 'все', 'время', 'один'],\n",
       " ['оттуда', 'мы', 'в', 'стадо', 'аргишили'],\n",
       " ['дедушка', 'это', 'кто', 'ходит', 'ломая', 'коряги', 'деревья'],\n",
       " ['сказала', 'это', 'самое']]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('low_resource_mt/datasets/evenki/tgt-train.txt') as evenki:\n",
    "    evenki = [x.strip().split() for x in evenki.readlines()]\n",
    "evenki[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['так', 'живем', 'сейчас'] ['так', 'живем', 'сейчас']\n",
      "['крепи', 'разжег', 'отец'] ['костры', 'разжег', 'отец']\n",
      "['потом', 'большой'] ['потом', 'большой']\n",
      "['говорит', 'если', 'лоси', 'потеряются'] ['говорит', 'если', 'олени', 'потеряются']\n",
      "['у', 'тебя', 'навык', 'большой'] ['у', 'тебя', 'опыт', 'большой']\n",
      "['я', 'в', 'нору', 'зашла'] ['я', 'в', 'берлогу', 'зашла']\n",
      "['там', 'один', 'или', 'два', 'годка', 'все', 'время', 'один'] ['там', 'один', 'или', 'два', 'года', 'все', 'время', 'один']\n",
      "['оттуда', 'мы', 'в', 'поголовье', 'аргишили'] ['оттуда', 'мы', 'в', 'стадо', 'аргишили']\n",
      "['дед', 'это', 'кто', 'ходит', 'ломая', 'коряги', 'деревья'] ['дедушка', 'это', 'кто', 'ходит', 'ломая', 'коряги', 'деревья']\n",
      "['сказала', 'это', 'самое'] ['сказала', 'это', 'самое']\n"
     ]
    }
   ],
   "source": [
    "for sent in evenki[:10]:\n",
    "    trans_sent = replace_nouns(sent)\n",
    "    print(trans_sent, sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['так', 'живем', 'сейчас'] ['так', 'живем', 'сейчас']\n",
      "['костры', 'разжег', 'отец'] ['костры', 'разжег', 'отец']\n",
      "nom sing\n",
      "['потом', 'больший'] ['потом', 'большой']\n",
      "['говорит', 'если', 'олени', 'потеряются'] ['говорит', 'если', 'олени', 'потеряются']\n",
      "nom sing\n",
      "['у', 'тебя', 'опыт', 'больший'] ['у', 'тебя', 'опыт', 'большой']\n",
      "['я', 'в', 'берлогу', 'зашла'] ['я', 'в', 'берлогу', 'зашла']\n",
      "nom sing\n",
      "['там', 'какой-то', 'или', 'два', 'года', 'все', 'время', 'один'] ['там', 'один', 'или', 'два', 'года', 'все', 'время', 'один']\n",
      "['оттуда', 'мы', 'в', 'стадо', 'аргишили'] ['оттуда', 'мы', 'в', 'стадо', 'аргишили']\n",
      "['дедушка', 'это', 'кто', 'ходит', 'ломая', 'коряги', 'деревья'] ['дедушка', 'это', 'кто', 'ходит', 'ломая', 'коряги', 'деревья']\n",
      "acc sing\n",
      "['сказала', 'это', 'само'] ['сказала', 'это', 'самое']\n"
     ]
    }
   ],
   "source": [
    "for sent in evenki[:10]:\n",
    "    trans_sent = replace_adjectives(sent)\n",
    "    print(trans_sent, sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['примерно', 'живем', 'сейчас'] ['так', 'живем', 'сейчас'] False\n",
      "['костры', 'разжег', 'отец'] ['костры', 'разжег', 'отец'] True\n",
      "['следом', 'большой'] ['потом', 'большой'] False\n",
      "['говорит', 'если', 'олени', 'потеряются'] ['говорит', 'если', 'олени', 'потеряются'] True\n",
      "['у', 'тебя', 'опыт', 'большой'] ['у', 'тебя', 'опыт', 'большой'] True\n",
      "['я', 'в', 'берлогу', 'зашла'] ['я', 'в', 'берлогу', 'зашла'] True\n",
      "['а там', 'один', 'или', 'два', 'года', 'все', 'время', 'один'] ['там', 'один', 'или', 'два', 'года', 'все', 'время', 'один'] False\n",
      "['оттудова', 'мы', 'в', 'стадо', 'аргишили'] ['оттуда', 'мы', 'в', 'стадо', 'аргишили'] False\n",
      "['дедушка', 'это', 'кто', 'ходит', 'ломая', 'коряги', 'деревья'] ['дедушка', 'это', 'кто', 'ходит', 'ломая', 'коряги', 'деревья'] True\n",
      "['сказала', 'это', 'самое'] ['сказала', 'это', 'самое'] True\n"
     ]
    }
   ],
   "source": [
    "for sent in evenki[:10]:\n",
    "    trans_sent = replace_adverbs(sent)\n",
    "    print(trans_sent, sent, trans_sent==sent)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
